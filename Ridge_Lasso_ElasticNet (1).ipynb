{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pre-defined Boston Dataset\n",
    "boston_dataset = datasets.load_boston()\n",
    "#print(boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\Binita Mandal\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  House Price  \n",
      "0     15.3  396.90   4.98         24.0  \n",
      "1     17.8  396.90   9.14         21.6  \n",
      "2     17.8  392.83   4.03         34.7  \n",
      "3     18.7  394.63   2.94         33.4  \n",
      "4     18.7  396.90   5.33         36.2  \n"
     ]
    }
   ],
   "source": [
    "#Load the data and divide into X and Y varaiable\n",
    "boston_pd = pd.DataFrame(boston_dataset.data) \n",
    "boston_pd.columns = boston_dataset.feature_names \n",
    "boston_pd_target = np.asarray(boston_dataset.target) \n",
    "boston_pd['House Price'] = pd.Series(boston_pd_target) \n",
    "\n",
    "# input \n",
    "X = boston_pd.iloc[:, :-1]\n",
    "#output \n",
    "Y = boston_pd.iloc[:, -1]\n",
    "print(boston_pd.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((379, 13), (379,), (127, 13), (127,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(boston_pd.iloc[:, :-1],\n",
    "                                                    boston_pd.iloc[:, -1],\n",
    "                                                    test_size=0.25)\n",
    "\n",
    "(x_train.shape, y_train.shape,x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared Error on test set :  19.683204345429633\n",
      "    Columns  Coefficient Estimate\n",
      "0      CRIM             -0.110428\n",
      "1        ZN              0.046065\n",
      "2     INDUS              0.033129\n",
      "3      CHAS              1.664020\n",
      "4       NOX            -19.211574\n",
      "5        RM              3.589481\n",
      "6       AGE              0.001809\n",
      "7       DIS             -1.406826\n",
      "8       RAD              0.327173\n",
      "9       TAX             -0.011220\n",
      "10  PTRATIO             -1.029281\n",
      "11        B              0.009534\n",
      "12    LSTAT             -0.540385\n"
     ]
    }
   ],
   "source": [
    "# Apply multiple Linear Regression Model \n",
    "lreg = LinearRegression() \n",
    "lreg.fit(x_train, y_train) \n",
    "\n",
    "# Generate Prediction on test set \n",
    "lreg_y_pred = lreg.predict(x_test) \n",
    "\n",
    "# calculating Mean Squared Error (mse) \n",
    "mean_squared_error = np.mean((lreg_y_pred - y_test)**2) \n",
    "print(\"Mean squared Error on test set : \", mean_squared_error) \n",
    "\n",
    "# Putting together the coefficient and their corrsponding variable names \n",
    "lreg_coefficient = pd.DataFrame() \n",
    "lreg_coefficient[\"Columns\"] = x_train.columns \n",
    "lreg_coefficient['Coefficient Estimate'] = pd.Series(lreg.coef_) \n",
    "print(lreg_coefficient) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10c598f3760>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(x='Coefficient Estimate' , y='Columns', data=lreg_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.668504551868303\n",
      "    Columns  Coefficient Estimate\n",
      "0      CRIM             -0.105061\n",
      "1        ZN              0.047216\n",
      "2     INDUS             -0.007132\n",
      "3      CHAS              1.482130\n",
      "4       NOX            -10.439683\n",
      "5        RM              3.674032\n",
      "6       AGE             -0.006156\n",
      "7       DIS             -1.281210\n",
      "8       RAD              0.299481\n",
      "9       TAX             -0.011422\n",
      "10  PTRATIO             -0.931837\n",
      "11        B              0.010058\n",
      "12    LSTAT             -0.550255\n"
     ]
    }
   ],
   "source": [
    "# import ridge regression from sklearn library \n",
    "from sklearn.linear_model import Ridge \n",
    "\n",
    "# Train the model \n",
    "ridgeR = Ridge(alpha = 1) \n",
    "ridgeR.fit(x_train, y_train) \n",
    "y_pred = ridgeR.predict(x_test) \n",
    "\n",
    "# calculate mean square error \n",
    "mean_squared_error_ridge = np.mean((y_pred - y_test)**2) \n",
    "print(mean_squared_error_ridge) \n",
    "\n",
    "# get ridge coefficient and print them \n",
    "ridge_coefficient = pd.DataFrame() \n",
    "ridge_coefficient[\"Columns\"]= x_train.columns \n",
    "ridge_coefficient['Coefficient Estimate'] = pd.Series(ridgeR.coef_) \n",
    "print(ridge_coefficient) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # import Lasso regression from sklearn library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error on test set 20.485589973537795\n",
      "    Columns  Coefficient Estimate\n",
      "0      CRIM             -0.100080\n",
      "1        ZN              0.048147\n",
      "2     INDUS             -0.031924\n",
      "3      CHAS              0.634313\n",
      "4       NOX             -2.917187\n",
      "5        RM              3.679364\n",
      "6       AGE             -0.011217\n",
      "7       DIS             -1.148973\n",
      "8       RAD              0.280777\n",
      "9       TAX             -0.011959\n",
      "10  PTRATIO             -0.854642\n",
      "11        B              0.010619\n",
      "12    LSTAT             -0.566930\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "\n",
    "# Train the model \n",
    "lasso = Lasso(alpha = 0.05) \n",
    "lasso.fit(x_train, y_train) \n",
    "y_pred1 = lasso.predict(x_test) \n",
    "\n",
    "# Calculate Mean Squared Error \n",
    "mean_squared_error = np.mean((y_pred1 - y_test)**2) \n",
    "print(\"Mean squared error on test set\", mean_squared_error) \n",
    "lasso_coeff = pd.DataFrame() \n",
    "lasso_coeff[\"Columns\"] = x_train.columns \n",
    "lasso_coeff['Coefficient Estimate'] = pd.Series(lasso.coef_) \n",
    "\n",
    "print(lasso_coeff) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # import Lasso regression from sklearn library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on test set 20.207174432737187\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Coefficient Estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.100846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.048732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.040699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>1.105161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-2.943213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.603752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.011688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.169891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.280880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.855945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.010463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.569259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Columns  Coefficient Estimate\n",
       "0      CRIM             -0.100846\n",
       "1        ZN              0.048732\n",
       "2     INDUS             -0.040699\n",
       "3      CHAS              1.105161\n",
       "4       NOX             -2.943213\n",
       "5        RM              3.603752\n",
       "6       AGE             -0.011688\n",
       "7       DIS             -1.169891\n",
       "8       RAD              0.280880\n",
       "9       TAX             -0.011800\n",
       "10  PTRATIO             -0.855945\n",
       "11        B              0.010463\n",
       "12    LSTAT             -0.569259"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model \n",
    "from sklearn.linear_model import ElasticNet \n",
    "\n",
    "# Train the model \n",
    "e_net = ElasticNet(alpha = .02,l1_ratio=.2) \n",
    "e_net.fit(x_train, y_train) \n",
    "\n",
    "# calculate the prediction and mean square error \n",
    "y_pred_elastic = e_net.predict(x_test) \n",
    "mean_squared_error = np.mean((y_pred_elastic - y_test)**2) \n",
    "print(\"Mean Squared Error on test set\", mean_squared_error) \n",
    "\n",
    "e_net_coeff = pd.DataFrame() \n",
    "e_net_coeff[\"Columns\"] = x_train.columns \n",
    "e_net_coeff['Coefficient Estimate'] = pd.Series(e_net.coef_) \n",
    "e_net_coeff \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
